# NOTE: Make sure all the paths are relative to the project root directory or absolute paths.

data:
  # There is wikipedia dataset as well but it can be used directly from datasets library
  news:
    path: data/news
    unzip: true # Download the data and unzip it
  wikipedia:
    path: data/wikipedia

preprocessing:
  stopwords:
    languages: [auto, english] # List of languages for stopword removal. Empty list means no stopword removal. "auto" means it will automatically look for language tag in the data file itself
  stemming:
    algorithm: porter # porter, lancaster, snowball, null (no stemming)
  lemmatization:
    algorithm: null   # wordnet, null (no lemmatization)
  lowercase: true
  remove_punctuation: true
  remove_numbers: true
  remove_special_characters: true

elasticsearch:
  host: localhost
  port: 9200
  scheme: http     # https for secure connection, http for local connection
  chunk_size: 500  # Number of documents to index in one bulk operation

redis:
  host: "localhost"
  port: 6379
  db: 0

cust_index_settings:
  info: TFIDF      # Kind of information indexed: BOOLEAN, WORDCOUNT or TFIDF
  dstore: CUSTOM   # Datastore choice: CUSTOM, ROCKSDB or REDIS
  compr: CODE      # Compression choice: NONE, CODE or CLIB
  optim: OPTIMISED # Optimisation choice: NONE, OPTIMISED
  qproc: TERM      # Query Processing choice: TERM or DOC

# news_attributes_indexed: [uuid, text]
# wikipedia_attributes_indexed: [id, text]

search_fields: [text]        # The field in the indexed documents to be searched (all fields to be searched must also be present in the 'attributes' list under 'index' section)
max_results: 50              # The number of top document IDs to retrieve for each query
max_num_documents: 10000     # Maximum number of documents to be processed from each dataset. Set to null to process all documents
top_k_words_threshold: 50    # Top K words to be plotted in frequency distribution plots
ranking_score_threshold: 0.1 # Minimum score threshold for a document to be considered relevant
output_dir: output
storage_dir: storage
temp_dir: temp
